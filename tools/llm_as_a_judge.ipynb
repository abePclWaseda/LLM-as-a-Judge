{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5dd3e48-5869-4c61-8165-28e259ad02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/bin/pip\n"
     ]
    }
   ],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd54831f-22f9-4228-91b4-c41905507c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.7.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision==0.22.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.7.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from torch==2.7.1) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from torch==2.7.1) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from torch==2.7.1) (3.1.6)\n",
      "Collecting fsspec (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "Collecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "Collecting nvidia-nccl-cu11==2.21.5 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.8.86 (from torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.3.1 (from torch==2.7.1)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting numpy (from torchvision==0.22.1)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.22.1)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.1)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from jinja2->torch==2.7.1) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (905.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.2/905.2 MB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m236.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, fsspec, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [torchaudio]2\u001b[0m [torchaudio]]-cu11]11]1]1]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.13.1 fsspec-2024.6.1 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.0.0 sympy-1.13.3 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c9a91a-2fe9-408a-bc79-67025fb97f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: filelock in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m214.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "Downloading regex-2025.9.18-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (802 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, hf-xet, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [transformers][0m [transformers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.10 huggingface-hub-0.35.3 regex-2025.9.18 safetensors-0.6.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a97e2f-829e-40c0-bbf2-fadeedea2cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acg17145sv/ondemand/data/sys/dashboard/batch_connect/sys/jupyter_app/jupyter_app/output/2bbad118-5705-47b1-afc0-5e7cc34f12d2/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "DEFAULT_MODEL = \"llm-jp/llm-jp-3.1-13b-instruct4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ec98b7-481b-4d0b-8b0c-ae750c9de61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338f2c4-e10e-4c1a-96a5-f71fb92f622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c229a6e-4497-4217-bd11-7b57a6b96cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:10<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"llm-jp/llm-jp-3.1-13b-instruct4\", device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f689766a-137e-47a9-9f64-15107e8b296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_text = (\"B: はい。\\nA: はい。\\nB: いろんな顔がありますね。\\nA: 私は1枚紙があって名前が書いてあります。\\nB: はいあっ構え書いてあるの。\\nA: 123456789。\\nB: はい。\\nA: 10人。\\nB: 12345678910人いますね。\\nA: あっじゃあぴったりですね。\\nB: はい。\\nB: そうですねはい。\\nA: はい。\\nB: えっと見たことある顔もあるし。\\nA: えっとはい。\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c6d447c-a45f-4d16-9c3a-1ca50271f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"\"\"\n",
    "あなたは日本語の会話品質の厳密評価者です。出力は必ず有効なJSONのみ。説明や前置きは書かないでください。\n",
    "重要：これは「音声会話の書き起こし」です。人間の会話には相づち（はい、ええ、うん等）、ためらい、言い直し、短い応答、重なり、言いよどみが自然に含まれます。\n",
    "これらは原則として減点対象ではありません。意味の通る範囲なら自然さやターン運用で加点し得ます。\n",
    "減点は、明確な意味破綻/無関連/機械的反復/会話の前進阻害などに限定します。\n",
    "{\n",
    "  \"coherence\": int,\n",
    "  \"naturalness\": int,\n",
    "  \"relevance\": int,\n",
    "  \"instruction_following\": int,\n",
    "  \"turn_taking\": int,\n",
    "  \"overall\": int,\n",
    "  \"rationale\": \"短い根拠説明\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "user_msg = f\"\"\"\n",
    "    \"次の会話出力を評価してください。これは人間同士の自然な音声会話の書き起こしです。\"\n",
    "    \"句読点や軽微な誤記は減点しないでください。相づちや短文応答は自然さとして許容します。\\n\\n\"\n",
    "\n",
    "    対話テキスト:\n",
    "    \\\"\\\"\\\"{dialogue_text}\\\"\\\"\\\"\"\"\".strip()\n",
    "\n",
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": system_msg},\n",
    "    {\"role\": \"user\", \"content\": system_msg + user_msg},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0588ed9c-84f2-46bf-a5e8-f3e93a99bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    chat, add_generation_prompt=True, tokenize=True, return_tensors=\"pt\"\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db133ec0-d1fd-4f02-a762-1ae19e758cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        inputs,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        do_sample=(0.7 > 0.0),\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.05,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc398d9b-6099-416b-a2ab-0ceb22fcc8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "\n",
      "あなたは日本語の会話品質の厳密評価者です。出力は必ず有効なJSONのみ。説明や前置きは書かないでください。\n",
      "重要：これは「音声会話の書き起こし」です。人間の会話には相づち（はい、ええ、うん等）、ためらい、言い直し、短い応答、重なり、言いよどみが自然に含まれます。\n",
      "これらは原則として減点対象ではありません。意味の通る範囲なら自然さやターン運用で加点し得ます。\n",
      "減点は、明確な意味破綻/無関連/機械的反復/会話の前進阻害などに限定します。\n",
      "{\n",
      "  \"coherence\": int,\n",
      "  \"naturalness\": int,\n",
      "  \"relevance\": int,\n",
      "  \"instruction_following\": int,\n",
      "  \"turn_taking\": int,\n",
      "  \"overall\": int,\n",
      "  \"rationale\": \"短い根拠説明\"\n",
      "}\n",
      "\"次の会話出力を評価してください。これは人間同士の自然な音声会話の書き起こしです。\"\n",
      "    \"句読点や軽微な誤記は減点しないでください。相づちや短文応答は自然さとして許容します。\n",
      "\n",
      "\"\n",
      "\n",
      "    対話テキスト:\n",
      "    \"\"\"B: はい。\n",
      "A: はい。\n",
      "B: いろんな顔がありますね。\n",
      "A: 私は1枚紙があって名前が書いてあります。\n",
      "B: はいあっ構え書いてあるの。\n",
      "A: 123456789。\n",
      "B: はい。\n",
      "A: 10人。\n",
      "B: 12345678910人いますね。\n",
      "A: あっじゃあぴったりですね。\n",
      "B: はい。\n",
      "B: そうですねはい。\n",
      "A: はい。\n",
      "B: えっと見たことある顔もあるし。\n",
      "A: えっとはい。\"\"\"\n",
      "\n",
      "### 応答:\n",
      "{\n",
      "  \"coherence\": 9,\n",
      "  \"naturalness\": 8,\n",
      "  \"relevance\": 8,\n",
      "  \"instruction_following\": 9,\n",
      "  \"turn_taking\": 9,\n",
      "  \"overall\": 9,\n",
      "  \"rationale\": \"会話は一貫して理解可能であり、自然さも保たれています。各発言が適切にターン運用され、意味の通らない部分はありません。\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output, skip_special_tokens=True).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ae7201f-ec27-4345-9cc9-f348d3572994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "自然言語処理とは何か\n",
      "\n",
      "### 応答:\n",
      "自然言語処理（Natural Language Processing, NLP）とは、コンピュータが人間の言語を理解し、生成し、操作する技術のことを指します。この分野は、人工知能（AI）や機械学習（ML）と密接に関連しており、以下のような主要なタスクを含みます：\n",
      "\n",
      "1. テキストの解析:\n",
      "   - 形態素解析: 単語や文節に分割し、それぞれの品詞を特定する。\n",
      "   - 構文解析: 文の構造を解析し、主語、\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"llm-jp/llm-jp-3.1-13b-instruct4\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"llm-jp/llm-jp-3.1-13b-instruct4\", device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"あなたは日本語の会話品質の厳密評価者です。出力は必ず有効なJSONのみ。説明や前置きは書かないでください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"自然言語処理とは何か\"},\n",
    "]\n",
    "tokenized_input = tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=True, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        tokenized_input,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.05,\n",
    "    )[0]\n",
    "print(tokenizer.decode(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f7394f6-038a-43bc-9c29-1b00a1f30606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\n",
      "\n",
      "### 指示:\n",
      "自然言語処理とは何か\n",
      "\n",
      "### 応答:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(chat, add_generation_prompt=True, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d276b2-182d-4049-afaf-176f986d2805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
